{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7ZNUN08c7uO"
      },
      "source": [
        "# Theoretical Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw7e068Sc7uQ"
      },
      "source": [
        "* This is the theoretical part of the final project. It includes theoretical questions from various topics covered in the course.\n",
        "* There are 7 questions among which you need to choose 6, according to the following key:\n",
        "    + Question 1 is **mandatory**.\n",
        "    + Choose **one question** from questions 2-3.\n",
        "    + Question 4 is **mandatory**.\n",
        "    + Questions 5-6 are **mandatory**.\n",
        "    + Question 7 is **mandatory**.\n",
        "* Question 1 is worth 15 points, whereas the other questions worth 7 points.\n",
        "* All in all, the maximal grade for this parts is 15+7*5=50 points.\n",
        "* **You should answer the questions on your own. We will check for plagiarism.**\n",
        "* If you need to add external images (such as graphs) to this notebook, please put them inside the 'imgs' folder. DO NOT put a reference to an external link.\n",
        "* Good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9B5GsL1c7uR"
      },
      "source": [
        "## Part 1: General understanding of the course material"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yEhVJrmc7uR"
      },
      "source": [
        "### Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwDLigT4c7uR"
      },
      "source": [
        "1.  Relate the number of parameters in a neural network to the over-fitting phenomenon (*).\n",
        "    Relate this to the design of convolutional neural networks, and explain why CNNs are a plausible choice for an hypothesis class for visual classification tasks.\n",
        "\n",
        "    (*) In the context of classical under-fitting/over-fitting in machine learning models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwapgMKyc7uS"
      },
      "source": [
        "#### Answer:\n",
        "More parameters in a neural network means that the learned metwork can be more complex and sueted to the training data we used in the training procces. <br>\n",
        "Complex model is much more prone to overfitting, since it can \"remember\" more specific relations from the training set thus overfitted to it. <br>\n",
        "If we consider the number of parameters of convolutional neural networks, this number depends on the number of layers (might be activation, pooling,  <br>\n",
        "fully connected, convulotion etc.), channels in each layer, kernel, stride and padding sizes. So increasing any of those parameter may lead to overfitting. <br>\n",
        "From the other hand, CNN tries to solve the overfitting phenomenon by reducing the number of parameters (versus FC for example) by using weighs in size of <br>\n",
        "kernel_size*kernel_size only instead of the entire size of the image as weighs. Another things is the fact the CNN let us detect pattern in given image by  <br>\n",
        "appling the kernel on the entire image, thus, finding pattern in the image regardless of its position in the images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBgTEsa3c7uS"
      },
      "source": [
        "2. Consider the linear classifier model with hand-crafted features:\n",
        "    $$f_{w,b}(x) = w^T \\psi(x) + b$$\n",
        "    where $x \\in \\mathbb{R}^2$, $\\psi$ is a non-learnable feature extractor and assume that the classification is done by $sign(f_{w,b}(x))$. Let $\\psi$ be the following feature extractor $\\psi(x)=x^TQx$ where $Q \\in \\mathbb{R}^{2 \\times 2}$ is a non-learnable positive definite matrix. Describe a distribution of the data which the model is able to approximate, but the simple linear model fails to approximate (hint: first, try to describe the decision boundary of the above classifier)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUuRVoVsc7uT"
      },
      "source": [
        "#### Answer:\n",
        "The decision boundry is achived when $$f_{w,b}(x) = 0$$ because the classification is done by $sign(f_{w,b}(x))$.\n",
        "So:  $$ f_{w,b}(x) = w^T \\psi(x) + b = w^T x^TQx + b = 0$$ <br>\n",
        "Which is equation from 2nd degree, meaninig the decision boundry is an hyperplane of 2nd degree.\n",
        "Thus, the distribution of the data which the model is able to approximate are linear (included in the space of 2nd degrees field) too,\n",
        "but it also can approx. data that it's features have up to 2nd degree relations between them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FmoThEoc7uT"
      },
      "source": [
        "3. Assume that we would like to train a Neural Network for classifying images into $C$ classes. Assume that the architecture can be stored in the memory as a computational graph with $N$ nodes where the output is the logits (namely, before applying softmax) for the current batch ($f_w: B \\times Ch \\times H \\times W \\rightarrow B \\times C$). Assume that the computational graph operates on *tensor* values.\n",
        "    * Implement the CE loss assuming that the labels $y$ are hard labels given in a LongTensor (as usual). **Use Torch's log_softmax and index_select functions** and implement with less as possible operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8bqyiHic7uU"
      },
      "source": [
        "#### Answer:\n",
        "$$ CE_LOSS(x, y) =  -1 \\cdot sum(y \\cdot log(model(x))) = -1 \\cdot sum(y \\cdot y_probs) $$ <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "imzBRqbac7uU"
      },
      "outputs": [],
      "source": [
        "from torch.nn.functional import log_softmax\n",
        "from torch import index_select\n",
        "import torch\n",
        "\n",
        "# in ordr to sccessfully run this NB we wrapped all functions. Arguments and return values are arbitrery\n",
        "\n",
        "# Input:  model, x, y.\n",
        "# Output: the loss on the current batch.\n",
        "def wrapper(model, x, y):\n",
        "    logits = model(x)\n",
        "    y_probs = log_softmax(input=logits, dim=1)\n",
        "    loss = -1 * torch.sum(index_select(input=y_probs, dim=1, incices=y))\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl-yQFulc7uV"
      },
      "source": [
        "* Using the model's function as a black box, draw the computational graph (treating both log_softmax and index_select as an atomic operations). How many nodes are there in the computational graph?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR9igofBc7uW"
      },
      "source": [
        "#### Answer:\n",
        "There will be 7 nodes or 8 if we consider the -1 constant for the sum:\n",
        "<center><img src=\"imgs/ce_loss.png\" /></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqpC0Yw0c7uW"
      },
      "source": [
        "* Now, instead of using hard labels, assume that the labels are representing some probability distribution over the $C$ classes. How would the gradient computation be affected? analyze the growth in the computational graph, memory and computation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OHxzOfbc7uW"
      },
      "source": [
        "#### Answer:\n",
        "Now the computational graph would look like this:\n",
        "<center><img src=\"imgs/ce_loss2.png\" /></center>\n",
        "\n",
        "Meaning we will must add another step to our gradient computation - the dot product between y and y_log_prob, as now it isn't one-hot and it means we must take into account the entire probabilties in the calc (when it was one-hot we could look only at one probability - 1).\n",
        "It means that both the memory and computation usage will be increased.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_YZPd8Oc7uW"
      },
      "source": [
        "* Apply the same analysis in the case that we would like to double the batch size. How should we change the learning rate of the optimizer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDvoUZgOc7uW"
      },
      "source": [
        "#### Answer:\n",
        "In case we would double the batches size, the gradient computation would stay (pretty much) the same but the gradient itself will be more accurate since we consider more samples in the batches. Also we would use more GPU mem at a given time, since we would like to store the data from the current batch. The computational graph will stay the same size but the operation will change (e.g. from sum of 16 values it would increase to sum of 32 values). Finally, the learning rate must be decreased in order to maintain roughly the same sizes of steps as before, since we aggragate the gradients of the batches (which we increased the size of them)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFLTmHNwc7uW"
      },
      "source": [
        "## Part 2: Optimization & Automatic Differentiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg6cMrYEc7uZ"
      },
      "source": [
        "### Question 2: resolving gradient conflicts in multi-task learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoDj_RKoc7uZ"
      },
      "source": [
        "Assume that you want to train a model to perform two tasks: task 1 and task 2.\n",
        "For each such task $i$ you have an already implemented function *loss\\_i = forward_and_compute_loss_i(model,inputs)* such that given the model and the inputs it computes the loss w.r.t task $i$ (assume that the computational graph is properly constructed). We would like to train our model using SGD to succeed in both tasks as follows: in each training iteration (batch) -\n",
        "* Let $g_i$ be the gradient w.r.t the $i$-th task.\n",
        "* If $g_1 \\cdot g_2 < 0$:\n",
        "    + Pick a task $i$ at random.\n",
        "    + Apply GD w.r.t only that task.\n",
        "* Otherwise:\n",
        "    + Apply GD w.r.t both tasks (namely $\\mathcal{L}_1 + \\mathcal{L}_2$).\n",
        "\n",
        "Note that in the above formulation the gradient is a thought of as a concatination of all the gradient w.r.t all the models parameters, and $g_1 \\cdot g_2$ stands for a dot product.\n",
        "\n",
        "What parts should be modified to implement the above? Is it the optimizer, the training loop or both? Implement the above algorithm in a code cell/s below"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Answer"
      ],
      "metadata": {
        "id": "hIjane0aFkJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import random\n",
        "\n",
        "def wrapper_2(Model, num_epochs, data_loader, forward_and_compute_loss_1, forward_and_compute_loss_2):\n",
        "\n",
        "    model = Model()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch in data_loader:\n",
        "            optimizer.zero_grad()\n",
        "            loss_1 = forward_and_compute_loss_1(model, batch)\n",
        "            loss_1.backward()\n",
        "            grad_1 = torch.cat([p.grad.view(-1) for p in model.parameters()])\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss_2 = forward_and_compute_loss_2(model, batch)\n",
        "            loss_2.backward()\n",
        "            grad_2 = torch.cat([p.grad.view(-1) for p in model.parameters()])\n",
        "\n",
        "            dot_product = torch.dot(grad_1, grad_2)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if dot_product < 0:\n",
        "                task_choice = random.choice([1, 2])\n",
        "                if task_choice == 1:\n",
        "                    final_loss = loss_1\n",
        "                else:\n",
        "                    final_loss = loss_2\n",
        "            else:\n",
        "                final_loss = (loss_1 + loss_2)\n",
        "\n",
        "            optimizer.step()\n",
        "            final_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return 0"
      ],
      "metadata": {
        "id": "lF7HFYr7-L1D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The primary component that needs modification is the training loop. The training loop has to be adapted to handle the complexities of multiple tasks, including computing the losses and gradients for each task, calculating the dot product of the gradients, and deciding which tasks to update based on that dot product.\n",
        "\n",
        "The optimizer, on the other hand, doesn't need to be modified. we can use a standard optimizer like SGD. It's the training loop that dictates how this optimizer is used, based on the specific conditions we set, such as the dot product of the gradients for the two tasks.\n",
        "\n",
        "So, in summary, it's primarily the training loop that needs to be customized to implement our multi-task training algorithm, while the optimizer can remain the same."
      ],
      "metadata": {
        "id": "YTtcYTFua3rK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W5n1U6_c7ua"
      },
      "source": [
        "### Question 3: manual automatic differentiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMDJ7jyCc7ua"
      },
      "source": [
        "Consider the following two-input two-output function:\n",
        "$$ f(x,y) = (x^2\\sin(xy+\\frac{\\pi}{2}), x^2\\ln(1+xy)) $$\n",
        "* Draw a computational graph for the above function. Assume that the unary atomic units are squaring, taking square root, $\\exp,\\ln$, basic trigonometric functions and the binary atomic units are addition and multiplication. You would have to use constant nodes.\n",
        "* Calculate manually the forward pass.\n",
        "* Calculate manually the derivative of all outputs w.r.t all inputs using a forward mode AD.\n",
        "* Calculate manually the derivative of all outputs w.r.t all inputs using a backward mode AD."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyaip3h2c7ua"
      },
      "source": [
        "## Part 3: Sequential Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfkvnF2Nc7ua"
      },
      "source": [
        "### Question 4: RNNs vs Transformers in the real life"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M26m8dpsc7ua"
      },
      "source": [
        "In each one of the following scenarios decide whether to use RNN based model or a transformer based model. Justify your choice.\n",
        "1. You are running a start-up in the area of automatic summarization of academic papers. The inference of the model is done on the server side, and it is very important for it to be fast.\n",
        "2. You need to design a mobile application that gathers small amount of data from few apps in every second and then uses a NN to possibly generate an alert given the information in the current second and the information from the past minute.\n",
        "3. You have a prediction task over fixed length sequences on which you know the following properties:\n",
        "    + In each sequence there are only few tokens that the model should attend to.\n",
        "    + Most of the information needed for generating a reliable prediction is located at the beginning of the sequence.\n",
        "    + There is no restriction on the computational resources."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer\n",
        "1: Transformer model\n",
        "\n",
        "In the context of running a start-up for the automatic summarization of academic papers, a Transformer-based model is the most suitable. Transformers are better at managing long sequences and capturing long-range dependencies, which are essential for summarizing academic papers effectively. Many of the early content of the paper (such as the research question answered throughout the paper, or maybe an experiment description presented at the beginning of it) is required at later parts, and  transformers do a better job at those long range dependencies. Additionally, since the inference is done on the server side, computational resources are less likely to be a constraint compared to a mobile application. The parallelizable nature of transformers also makes the inference process faster, which is most impotant for server-side applications.\n",
        "\n",
        "2: RNN model\n",
        "\n",
        "For designing a mobile application that gathers a small amount of data from a few apps every second and then uses a neural network to possibly generate an alert, an RNN model is the most suitable. The main reason is the limited computational resources that are available on mobile phones. RNNs generally have lees computations and so are more efficient than transformers. RNN are capable of handeling this task with good results since the task involves real-time analysis of a small amount of sequential data, so long relations are not needed to have much weight on the alert desicion.\n",
        "\n",
        "3: Transformer model\n",
        "\n",
        "In a prediction task over fixed length sequences where only a few tokens are important for generating a reliable prediction, a Transformer model is the most suitable. The main reason is that most of the information needed for generating a reliable prediction is located at the beginning of the sequence, and transformers can easily attend to these important tokens and give them higher considerability that other tokens.In addition,In each sequence there are only few tokens that the model should attend to, and transformers are capable of this task using its attention mechanism. Moreover, there are no restrictions on computational resources, so RNN have a disadvantage compared to the more complex and generally flexible transformer."
      ],
      "metadata": {
        "id": "clmk5G5AV-w2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0o2RrTjc7ub"
      },
      "source": [
        "## Part 4: Generative modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxHbGiRnc7ub"
      },
      "source": [
        "### Question 5: VAEs and GANS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O4f83wmc7ub"
      },
      "source": [
        "Suggest a method for combining VAEs and GANs. Focus on the different components of the model and how to train them jointly (the objectives). Which drawbacks of these models the combined model may overcome? which not?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer\n",
        "\n",
        "**Structure of the combined model:**\n",
        "\n",
        "The combined VAE with GAN model integrates the components of both Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs). It consists of an encoder, a decoder, and a discriminator. The encoder maps input data samples to a latent space, producing parameters for a latent variable distribution. The decoder, acting as the generator in this combined framework, takes points from the latent space and reconstructs data samples. The discriminator's role is to differentiate between genuine data samples and those generated by the decoder.\n",
        "\n",
        "Training the combined VAE with GAN model involves optimizing multiple objectives concurrently. The encoder and decoder are trained using the VAE's reconstruction loss and the KL Divergence. The decoder also aims to act as the generator part of the GAN, and generate samples that try and fool the discriminator, similar to the generator's objective in traditional GANs. The discriminator is trained to correctly classify real samples and distinguish them from the fake samples produced by the decoder. The joint loss function for the encoder and decoder can be represented as:\n",
        "$$ \\text{Loss}_{\\text{combined}} = \\text{Reconstruction Loss} + \\lambda \\times \\text{KL Divergence} - \\gamma \\times \\text{Generator Loss} $$\n",
        "Where:\n",
        "- Reconstruction Loss: Measures how well the decoder can recreate the original input after encoding and decoding.\n",
        "- KL Divergence: Penalizes the encoder if the latent variable distribution deviates from a standard normal distribution.\n",
        "- Generator Loss: Encourages the decoder to produce samples that the discriminator classifies as real.\n",
        "- $\\lambda$ and $\\gamma$ : Hyperparameters that balance the contribution of each component to the overall loss.\n",
        "\n",
        "**Drawbacks overcome by the combined model:**\n",
        "\n",
        "Both VAEs and GANs have their own challenges. VAEs may ensure a structured latent space, although it often produce blurrier generated images compared to GANs. GANs, on the other hand, are known for generating high-quality, sharp images but can suffer from training instability and mode collapse. By combining VAEs and GANs, the model can leverage the strengths of both architectures. The structured latent space of VAEs can aid in the stable training of GANs, while the GAN component can enhance the sharpness and quality of the samples produced by the VAE.\n",
        "\n",
        "**Drawbacks the combined model my not overcome:**\n",
        "\n",
        "Despite the advantages of the combined VAE with GAN approach, some challenges are present. The combined model becomes more complex, introducing additional hyperparameters like $ \\lambda $ and $ \\gamma $ that need careful tuning. This can make the training process more complex and sensitive to hyperparameter values. Moreover, while the combined model can better handle issues like mode collapse to an extent, it's not entirely immune to it. Balancing the objectives of reconstruction, KL divergence, and generation might lead to neither being optimized perfectly. The combined model might still require more computational resources and time to train due to the added complexity.\n"
      ],
      "metadata": {
        "id": "55riTgXzU41Y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy0_9cUFc7ub"
      },
      "source": [
        "### Question 6: Diffusion Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhDViH6Ec7ub"
      },
      "source": [
        "Show that $q(x_{t-1}|x_t,x_0)$ is tractable and is given by $\\mathcal{N}(x_{t-1};\\tilde{\\mu}(x_t,x_0),\\tilde{\\beta_t}I)$ where the terms for $\\tilde{\\mu}(x_t,x_0)$ and $\\tilde{\\beta_t}$ are given in the last tutorial. Do so by explicitly computing the PDF."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Answer\n",
        "From the last tutorial:\n",
        "$$ \\tilde{\\mu}(x_t,x_0) := \\frac{\\sqrt{\\bar{\\alpha}_{t-1}}\\beta_t}{1-\\bar{\\alpha}_t}x_0 + \\frac{\\sqrt{\\alpha_t}(1-\\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}x_t$$\n",
        "and:\n",
        "$$\\tilde{\\beta}_t := \\frac{1-\\bar{\\alpha}_{t-1}}{1-\\bar{\\alpha}_t}\\beta_t$$\n",
        "\n",
        "Lets look at the Gaussian distribution:\n",
        "$$ q(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} $$\n",
        "\n",
        "Lets condiser $ \\tilde{\\mu}(x_t,x_0) = μ,    \\tilde{\\beta}_t = \\sigma^2   $\n",
        " and assign the given valus to the dist:\n",
        "\n",
        "$$ q(x_{t-1}|x_t,x_0) = \\frac{1}{\\sqrt{2\\pi\\tilde{\\beta}_t}} e^{-\\frac{(x_{t-1}-\\tilde{\\mu}(x_t,x_0))^2}{2\\tilde{\\beta}_t}} =$$\n",
        "\n",
        "$$= \\frac{1}{\\sqrt{2\\pi\\frac{1-\\bar{\\alpha}_{t-1}}{1-\\bar{\\alpha}_t}\\beta_t}} e^{-\\frac{(x_{t-1}-\\tilde{\\mu}(x_t,x_0))^2}{2\\frac{1-\\bar{\\alpha}_{t-1}}{1-\\bar{\\alpha}_t}\\beta_t}} $$\n",
        "\n",
        "\n",
        "The expression represents a Gaussian distribution with the specified mean and variance, confirming its tractability. This confirms that $ q(x_{t-1}|x_t,x_0) $ is tractable and is given by $ N(x_{t-1};\\tilde{\\mu}(x_t,x_0),\\tilde{\\beta}_t I) $."
      ],
      "metadata": {
        "id": "_YVFhS9UA-N_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwU3YD4Uc7ub"
      },
      "source": [
        "## Part 5: Training Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3tjxONHc7ub"
      },
      "source": [
        "### Question 7: Batch Normalization and Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTli4KZ3c7ub"
      },
      "source": [
        "For both BatchNorm and Dropout analyze the following:\n",
        "1. How to use them during the training phase (both in forward pass and backward pass)?\n",
        "2. How differently they behave in the inference phase? How to distinguish these operation modes in code?\n",
        "3. Assume you would like to perform multi-GPU training (*) to train your model. What should be done in order for BatchNorm and dropout to work properly? assume that each process holds its own copy of the model and that the processes can share information with each other.\n",
        "\n",
        "(*): In a multi-GPU training each GPU is associated with its own process that holds an independent copy of the model. In each training iteration a (large) batch is split among these processes (GPUs) which compute the gradients of the loss w.r.t the relevant split of the data. Afterwards, the gradients from each process are then shared and averaged so that the GD would take into account the correct gradient and to assure synchornization of the model copies. Note that the proccesses are blocked between training iterations."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer\n",
        "\n",
        "**BatchNorm:**\n",
        "\n",
        "In the training phase of BatchNorm, the activations of each layer in a mini-batch are normalized during the forward pass.For each feature we subtract the mean and dividing by the standard deviation in order to normalized the batch. We also keep the moving averages of the mean and variance for each feature for later use during inference. The normalized activations are then processed through the activation function, which yields results for further computation in the network. In the optimization process, gradients related to the normalized activations, gamma, and beta are computed in the backward pass(the batchNorm hyperparameters handeling the scaling and shifting respectevly)\n",
        "\n",
        "In the inference phase, the mean and variance of the activations for each feature channel in a mini-batch are not computed. We instead use the moving averages of the mean and variance (which we recorded during training) are used to normalize the activations. This ensures consistency in the normalization process and makes the inference more stable. The normalized values are then adjusted using the learned parameters, gamma and beta.\n",
        "\n",
        "With multi-GPU BatchNorm training, the forward pass sees each GPU computing its batch statistics independently. After the forward pass on every GPU, the statistics(mean and variance) are averaged across all GPUs. This ensures a consistent normalization approach(There are less common types of combining the statistics like weighted average). These syncronized statistics are then used for normalization on each GPU during both the forward and backward passes. To maintain uniformity, the gamma and beta parameters should be synchronized or shared among all GPUs.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Dropout:**\n",
        "\n",
        "In the dropout training phase, during the forward pass, a fraction of the activations is randomly set to zero, in order to prevent potential overfitting. We us the dropout rate hyperparameter to set the probability of each neuron being dropped out. In the backward pass, however, gradients are computed as if they remained active even if ther were dropped out. This means that the gradients remain unaffected by the dropout process.\n",
        "\n",
        "In the inference phase of dropout,generally all neurons are functioning to ensure inference is using all the learnt weights. However, a key point to note is the potential need for weight scaling during this phase. This adjustment is often done by multiplying the weights by the dropout rate.\n",
        "\n",
        "With multi GPU training using dropout, we need to make sure that all GPUs are working on the same dropout state- the same dropout mask. If the mask is generated at random, we can use a shared random seed or by synchronizing the masks between all the GPUs, in order to achive it.\n"
      ],
      "metadata": {
        "id": "5qoxh-6lYxY4"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}